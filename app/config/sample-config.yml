dataset:
  directory: ../dataset/
  vocabulary_treshold: 10
  image_resize: 224
  shuffle: False
  num_workers: 8 # ... minutes

training:
  gpu_id: 0 # specify the GPU id for learning process
  batch_size: 64 # the number of data contained in every batch
  epoch: 10
  learning_rate: 0.001
  weight_decay: 0.000001
  overfit_warning: 5

model:
  encoder:
    linear_visual_features:
      out_size: 1024
    lstm:
      hidden_size: 512
      num_layers: 2
      bidirectional: True 
  decoder:
    lstm:
      embeed_size: 256 # output from embedded layer
      hidden_size: 512
      num_layers: 2


logging:
  save_model_dir: _models/
  print_interval: 10
  tensorboard: _logger/
  wandb: False
  wandb-project: wandb-project-name
   